{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/RubenQuispe/Machine-Learning-con-Python-001/blob/master/Lab_12_Log%C3%ADstica_Regresi%C3%B3n.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hMaEfqwaJklN"
   },
   "source": [
    "# Log√≠stica Regresi√≥n con Python Para Predecir el Abandono de Clientes\n",
    "## Creado por [M.Sc. Ruben Quispe](https://www.linkedin.com/in/msc-rub%C3%A9n-quispe-l/)\n",
    "\n",
    "## Curso: [Machine Learning con Python](https://eie.pe/curso-machine-learning/)\n",
    "# Objetivos\n",
    "Despu√©s de completar esta pr√°ctica de laboratorio, podr√°:\n",
    "\n",
    "* Utilice scikit Logistic Regression para clasificar\n",
    "* Entender la matriz de confusi√≥n.\n",
    "\n",
    "En este notebook, aprender√° Regresi√≥n log√≠stica y, luego, crear√° un modelo para una empresa de telecomunicaciones, para predecir cu√°ndo sus clientes se ir√°n a un competidor, para que puedan tomar alguna acci√≥n para retener a los clientes.\n",
    "\n",
    "# Tabla de contenidos\n",
    "1. Sobre el dataset\n",
    "2. Selecci√≥n y Pre-procesamiento de Data\n",
    "3. Modelado (Regresi√≥n Log√≠stica con scikit learn)\n",
    "4. Evaluaci√≥n\n",
    "5. Pr√°ctica\n",
    "\n",
    "# ¬øCu√°l es la diferencia entre Regresi√≥ Lineal y Log√≠stica\n",
    "Si bien la regresi√≥n lineal es adecuada para estimar valores continuos (por ejemplo, estimar el precio de la vivienda), no es la mejor herramienta para predecir la clase de un punto de datos observado. Para estimar la clase de un punto de datos, necesitamos alg√∫n tipo de orientaci√≥n sobre cu√°l ser√≠a la clase m√°s probable para ese punto de datos. Para ello utilizamos Regresi√≥n log√≠stica.\n",
    "\n",
    "# Recuerde la regresi√≥n lineal:\n",
    "\n",
    "Como sabe, la regresi√≥n lineal encuentra una funci√≥n que relaciona una variable dependiente continua, y, con algunos predictores (variables independientes ùë•1, ùë•2, etc.). Por ejemplo, la regresi√≥n lineal simple asume una funci√≥n de la forma:\n",
    "$$ y= \\theta_0+ \\theta_1 x_1 + \\theta_2 x_2 + \\cdots $$\n",
    "y encuentra los valores de los par√°metros $ \\theta_0, \\theta_1, \\theta_2$\n",
    " , etc., donde el t√©rmino $\\theta_0$ es la \"intersecci√≥n\". Generalmente se puede mostrar como: \n",
    "$$ h_\\theta(x) = \\theta^TX $$\n",
    "La regresi√≥n log√≠stica es una variaci√≥n de la regresi√≥n lineal, √∫til cuando la variable dependiente observada, y, es categ√≥rica. Produce una f√≥rmula que predice la probabilidad de la etiqueta de clase en funci√≥n de las variables independientes.\n",
    "\n",
    "La regresi√≥n log√≠stica se ajusta a una curva especial en forma de s tomando la regresi√≥n lineal y transformando la estimaci√≥n num√©rica en una probabilidad con la siguiente funci√≥n, que se llama funci√≥n sigmoidea ùúé:\n",
    "\n",
    "$$ h_\\theta(x) = \\sigma({\\theta^TX}) = \\frac{e^{(\\theta_0 + \\theta_1 x_1 +\\theta_2 x_2 + ...)}}{1+e^{(\\theta_0 + \\theta_1 x_1 +\\theta_2 x_2 + \\cdots)}} $$ or:\n",
    "$$\n",
    "ProbabilityOfaClass_1 =  P(Y=1|X) = \\sigma({\\theta^TX}) = \\frac{e^{\\theta^TX}}{1+e^{\\theta^TX}} \n",
    "$$\n",
    "En esta ecuaci√≥n, ${\\theta^TX}$ es el resultado de la regresi√≥n (la suma de las variables ponderadas por los coeficientes), exp es la funci√≥n exponencial y $\\sigma(\\theta^TX)$ es la [funci√≥n sigmoidea o log√≠stica](https://en.wikipedia.org/wiki/Logistic_function?cm_mmc=Email_Newsletter-_-Developer_Ed%2BTech-_-WW_WW-_-SkillsNetwork-Courses-IBMDeveloperSkillsNetwork-ML0101EN-SkillsNetwork-20718538&cm_mmca1=000026UJ&cm_mmca2=10006555&cm_mmca3=M12345678&cvosrc=email.Newsletter.M12345678&cvo_campaign=000026UJ&cm_mmc=Email_Newsletter-_-Developer_Ed%2BTech-_-WW_WW-_-SkillsNetwork-Courses-IBMDeveloperSkillsNetwork-ML0101EN-SkillsNetwork-20718538&cm_mmca1=000026UJ&cm_mmca2=10006555&cm_mmca3=M12345678&cvosrc=email.Newsletter.M12345678&cvo_campaign=000026UJ&cm_mmc=Email_Newsletter-_-Developer_Ed%2BTech-_-WW_WW-_-SkillsNetwork-Courses-IBMDeveloperSkillsNetwork-ML0101EN-SkillsNetwork-20718538&cm_mmca1=000026UJ&cm_mmca2=10006555&cm_mmca3=M12345678&cvosrc=email.Newsletter.M12345678&cvo_campaign=000026UJ&cm_mmc=Email_Newsletter-_-Developer_Ed%2BTech-_-WW_WW-_-SkillsNetwork-Courses-IBMDeveloperSkillsNetwork-ML0101EN-SkillsNetwork-20718538&cm_mmca1=000026UJ&cm_mmca2=10006555&cm_mmca3=M12345678&cvosrc=email.Newsletter.M12345678&cvo_campaign=000026UJ), tambi√©n llamada curva log√≠stica. Es una forma de \"S\" com√∫n (curva sigmoidea).\n",
    "\n",
    "Entonces, brevemente, la regresi√≥n log√≠stica pasa la entrada a trav√©s del log√≠stico / sigmoide, pero luego trata el resultado como una probabilidad:\n",
    "Entonces, brevemente, la regresi√≥n log√≠stica pasa la entrada a trav√©s del log√≠stico / sigmoide, pero luego trata el resultado como una probabilidad:\n",
    "\n",
    "![](https://public.boxcloud.com/d/1/b1!1Ubvh33mbloPsU8cMZ9CAMd36coW_r1NH4RSIqy1PxTyzswDLgkxpY13A41JiMzhm4xZ9CZsnzozOIeIufQBDylL4Mt8xyJF7Cwb5HsFYF7CYbzCffyzLIYkt0LH82d792NgZpo3mHnV4bsVOef4z8OasulsFLJU70pvsppYeYs-Sbq8YmJejbT5i3DeFOu9PQEnYNQ93Ga_eArJwt0k2562P3JJLjQF5kItREp76piD2iOSKbejn4c_7t4rYXEEuVAt_pac8aQ1JNO93mczljonjJK98lW0hBWixfOl5yOhQYmFKUJu0_2VNQ3h_uSYbeuQRpn2L2oWJfjRGMcUX_4TaAxOXLN7YEMkBouJqdvacWe3KgkIPlPzeozJTAWiFo4WcO1C-_afUlozxUz8PWPuOe_9IRRyboTpxawgA49-p-vYv08wxA6bP3Zuhb22HoJLigpJQGdtqGy1hEYij9IDFdEpe_2IQrvaq7AVafLpZqWcikAFHx58jvG17PIjCVLxr-_V_D1x2s-qmU2Bo3SsdFQGeSFTh8HJj4HImWCXxr_x5Uf729zPxn-LWqWL4MZCV_yzipZorljiz-tfIeH-vdIWhdvQ_d7I4Zv6LYAJ4PT8IaNP3Yz2HLhxISQlLdqV-SknwyXk18RMWDqv2hDII8gZiRSC8Hn52YzFlR2PZvLyltiEr0HgFxt9V9T101y66RRsLOAMpybjZ6I9_6SFlYD0DAxsrDJoJYEF1jqsGF9w-92sRx78yIGxXUSCMN9gmQN2BAPnuoJjIrd3iEdwsFvZzKXyo8h9krnX1TkKH5mvk9VeolFXTPID8eaMyLod3FAB2O1xT77cGGJU6Mfq-A07HuueqFkIYqAMoIDgTFIPzYiYyAVnpV9WBrWHULYg8P5txEyF2AmEHrOt1vh9Lud4AeEFzxYTXGFuD9vQhJ_97L7QYLEEAgS_pvAUUbOi3aMLiVlnFDh3LY6Q5ZNER2CpcEpYYXP0t6eQC2GziqlNzrsT2Uh9C6hacv2PWqLtzot4X-O4ZOF8KeugNZzdNg66Seqz1FfwZ_hUOYwyKdTO2mqL-ulIbbhcPhKkzN5FK8Kk1ELKuo_q83WDfHkXC7qHpUFryL6a8LWkjnf2tJ8lpOTh0TSyvlxWg2lKfCuTwtt69X464AmmDxiSvzVRbn43zYOZqlxK7SrsGXBT5uNZU9rltacLGuZUuBwjY8x_e9OgsN847JL1zojnEiA32zoz35zrdGeIlaAjWHWV_1wXzHKhwezn1dpyb1gueKDPi9C8UiLlFFFG_RK0GQHgH_RlLmwYsl1Nkm4thuj2JXcr46I_AXDk08t8SMuqsbBSwseSjAz_YvPjHH6mhG3tv9_Fsku99RdSeAyrjLmVG456QgDSjMQavT_fY-fOo98QbmPqGYX7IaklMSAK_MCuZufFVFHM-qalK7ZxaQ2-_l9bqywKgpREdteMQGR09g../download)\n",
    "<img\n",
    "src=\"https://ibm.box.com/shared/static/kgv9alcghmjcv97op4d6onkyxevk23b1.png\" width=\"400\" align=\"center\">\n",
    "El objetivo del algoritmo de Regresi√≥n Log√≠stica, es encontrar los mejores par√°metros Œ∏, para ‚ÑéùúÉ (ùë•) = ùúé (ùúÉùëáùëã), de tal manera que el modelo prediga mejor la clase de cada caso.\n",
    "\n",
    "# Rotaci√≥n de clientes con regresi√≥n log√≠stica\n",
    "A una empresa de telecomunicaciones le preocupa la cantidad de clientes que abandonan su negocio de telefon√≠a fija por competidores de cable. Necesitan entender qui√©n se va. Imagine que es analista en esta empresa y tiene que averiguar qui√©n se va y por qu√©.\n",
    "\n",
    "# 1. Primero importemos las bibliotecas necesarias:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "PoGAVJLVJrdr"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pylab as pl\n",
    "import numpy as np\n",
    "import scipy.optimize as opt\n",
    "from sklearn import preprocessing\n",
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T-dtEC1aVsvW"
   },
   "source": [
    "# Sobre el conjunto de datos\n",
    "Usaremos un conjunto de datos de telecomunicaciones para predecir la p√©rdida de clientes. Este es un conjunto de datos de clientes hist√≥ricos donde cada fila representa un cliente. Los datos son relativamente f√°ciles de entender y es posible que descubra informaci√≥n que puede utilizar de inmediato. Por lo general, es menos costoso mantener clientes que adquirir nuevos, por lo que el enfoque de este an√°lisis es predecir los clientes que permanecer√°n en la empresa.\n",
    "Este conjunto de datos proporciona informaci√≥n para ayudarlo a predecir qu√© comportamiento lo ayudar√° a retener clientes. Puede analizar todos los datos relevantes de los clientes y desarrollar programas de retenci√≥n de clientes enfocados.\n",
    "\n",
    "El conjunto de datos incluye informaci√≥n sobre:\n",
    "\n",
    "* Clientes que se fueron en el √∫ltimo mes: la columna se llama Renuncia\n",
    "* Servicios a los que cada cliente se ha suscrito: tel√©fono, varias l√≠neas, Internet, seguridad en l√≠nea, respaldo en l√≠nea, protecci√≥n de dispositivos, soporte t√©cnico y transmisi√≥n de TV y pel√≠culas.\n",
    "* Informaci√≥n de la cuenta del cliente: cu√°nto tiempo ha sido cliente, contrato, m√©todo de pago, facturaci√≥n electr√≥nica, cargos mensuales y cargos totales\n",
    "* Informaci√≥n demogr√°fica sobre los clientes: sexo, rango de edad y si tienen socios y dependientes\n",
    "# 2. Cargue los datos de Telco Churn\n",
    "Telco Churn es un archivo de datos hipot√©ticos sobre los esfuerzos de una empresa de telecomunicaciones para reducir la rotaci√≥n de su base de clientes. Cada caso corresponde a un cliente separado y registra diversa informaci√≥n demogr√°fica y de uso del servicio. Antes de poder trabajar con los datos, debe usar la URL para obtener ChurnData.csv.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "id": "IYqsXlxRVjaz",
    "outputId": "14ec67de-1cfe-43ab-c5a4-96065adea999"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tenure</th>\n",
       "      <th>age</th>\n",
       "      <th>address</th>\n",
       "      <th>income</th>\n",
       "      <th>ed</th>\n",
       "      <th>employ</th>\n",
       "      <th>equip</th>\n",
       "      <th>callcard</th>\n",
       "      <th>wireless</th>\n",
       "      <th>longmon</th>\n",
       "      <th>...</th>\n",
       "      <th>pager</th>\n",
       "      <th>internet</th>\n",
       "      <th>callwait</th>\n",
       "      <th>confer</th>\n",
       "      <th>ebill</th>\n",
       "      <th>loglong</th>\n",
       "      <th>logtoll</th>\n",
       "      <th>lninc</th>\n",
       "      <th>custcat</th>\n",
       "      <th>churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.40</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.482</td>\n",
       "      <td>3.033</td>\n",
       "      <td>4.913</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.45</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.246</td>\n",
       "      <td>3.240</td>\n",
       "      <td>3.497</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.841</td>\n",
       "      <td>3.240</td>\n",
       "      <td>3.401</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>38.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.05</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.800</td>\n",
       "      <td>3.807</td>\n",
       "      <td>4.331</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.960</td>\n",
       "      <td>3.091</td>\n",
       "      <td>4.382</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   tenure   age  address  income   ed  employ  equip  callcard  wireless  \\\n",
       "0    11.0  33.0      7.0   136.0  5.0     5.0    0.0       1.0       1.0   \n",
       "1    33.0  33.0     12.0    33.0  2.0     0.0    0.0       0.0       0.0   \n",
       "2    23.0  30.0      9.0    30.0  1.0     2.0    0.0       0.0       0.0   \n",
       "3    38.0  35.0      5.0    76.0  2.0    10.0    1.0       1.0       1.0   \n",
       "4     7.0  35.0     14.0    80.0  2.0    15.0    0.0       1.0       0.0   \n",
       "\n",
       "   longmon  ...  pager  internet  callwait  confer  ebill  loglong  logtoll  \\\n",
       "0     4.40  ...    1.0       0.0       1.0     1.0    0.0    1.482    3.033   \n",
       "1     9.45  ...    0.0       0.0       0.0     0.0    0.0    2.246    3.240   \n",
       "2     6.30  ...    0.0       0.0       0.0     1.0    0.0    1.841    3.240   \n",
       "3     6.05  ...    1.0       1.0       1.0     1.0    1.0    1.800    3.807   \n",
       "4     7.10  ...    0.0       0.0       1.0     1.0    0.0    1.960    3.091   \n",
       "\n",
       "   lninc  custcat  churn  \n",
       "0  4.913      4.0    1.0  \n",
       "1  3.497      1.0    1.0  \n",
       "2  3.401      3.0    0.0  \n",
       "3  4.331      4.0    0.0  \n",
       "4  4.382      3.0    0.0  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "churn_df = pd.read_csv(\"D:/TECHNOLOGY 2020/Data/ChurnData.csv\")\n",
    "churn_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eu_7rCOKXZ9y",
    "outputId": "c2d396a7-6d0b-4ef2-9a08-4656849c3fd3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 28)"
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "churn_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V6fFc-0RXw-7"
   },
   "source": [
    "# 3. Data Preprocesamiento y selecci√≥n \n",
    "Seleccionemos algunas caracter√≠sticas para el modelado. Tambi√©n cambiamos el tipo de datos de destino para que sea entero, ya que es un requisito del algoritmo skitlearn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "id": "moglj6csYM4x",
    "outputId": "d10845e1-6cf0-4488-e4ac-4d6dd670af25"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tenure</th>\n",
       "      <th>age</th>\n",
       "      <th>address</th>\n",
       "      <th>income</th>\n",
       "      <th>ed</th>\n",
       "      <th>employ</th>\n",
       "      <th>equip</th>\n",
       "      <th>callcard</th>\n",
       "      <th>wireless</th>\n",
       "      <th>churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>38.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tenure   age  address  income   ed  employ  equip  callcard  wireless  \\\n",
       "0    11.0  33.0      7.0   136.0  5.0     5.0    0.0       1.0       1.0   \n",
       "1    33.0  33.0     12.0    33.0  2.0     0.0    0.0       0.0       0.0   \n",
       "2    23.0  30.0      9.0    30.0  1.0     2.0    0.0       0.0       0.0   \n",
       "3    38.0  35.0      5.0    76.0  2.0    10.0    1.0       1.0       1.0   \n",
       "4     7.0  35.0     14.0    80.0  2.0    15.0    0.0       1.0       0.0   \n",
       "\n",
       "   churn  \n",
       "0      1  \n",
       "1      1  \n",
       "2      0  \n",
       "3      0  \n",
       "4      0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "churn_df = churn_df[['tenure', 'age', 'address', 'income', 'ed', 'employ', 'equip',   'callcard', 'wireless','churn']]\n",
    "churn_df['churn'] = churn_df['churn'].astype('int')\n",
    "churn_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_5swG4k_YlRt"
   },
   "source": [
    "# Pr√°ctica\n",
    "¬øCu√°ntas filas y columnas hay en este conjunto de datos en total? ¬øC√≥mo se llaman las columnas?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bXSh7L_kYxqB",
    "outputId": "337cf4a0-1215-41e1-9449-aaca59d39b1b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 10)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# write your code here\n",
    "churn_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SvJUG2U4YlPl"
   },
   "source": [
    "Definamos X e y para nuestro conjunto de datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rbPWbY-6Xcy5",
    "outputId": "7737ceb5-0442-44dd-d44f-e2f3213cf8b7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 11.,  33.,   7., 136.,   5.,   5.,   0.],\n",
       "       [ 33.,  33.,  12.,  33.,   2.,   0.,   0.],\n",
       "       [ 23.,  30.,   9.,  30.,   1.,   2.,   0.],\n",
       "       [ 38.,  35.,   5.,  76.,   2.,  10.,   1.],\n",
       "       [  7.,  35.,  14.,  80.,   2.,  15.,   0.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.asarray(churn_df[['tenure', 'age', 'address', 'income', 'ed', 'employ', 'equip']])\n",
    "X[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ADaDCHHEXi3a",
    "outputId": "b592e18d-a4ea-439e-8514-138c7e6b105e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 0, 0])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.asarray(churn_df['churn'])\n",
    "y [0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LjIK1v8rZjq1"
   },
   "source": [
    "Adem√°s, normalizamos el conjunto de datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W0ebpSShZkPM",
    "outputId": "0beea708-cab8-4822-9227-224c9a1b39ad"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.13518441, -0.62595491, -0.4588971 ,  0.4751423 ,  1.6961288 ,\n",
       "        -0.58477841, -0.85972695],\n",
       "       [-0.11604313, -0.62595491,  0.03454064, -0.32886061, -0.6433592 ,\n",
       "        -1.14437497, -0.85972695],\n",
       "       [-0.57928917, -0.85594447, -0.261522  , -0.35227817, -1.42318853,\n",
       "        -0.92053635, -0.85972695],\n",
       "       [ 0.11557989, -0.47262854, -0.65627219,  0.00679109, -0.6433592 ,\n",
       "        -0.02518185,  1.16316   ],\n",
       "       [-1.32048283, -0.47262854,  0.23191574,  0.03801451, -0.6433592 ,\n",
       "         0.53441472, -0.85972695]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "X = preprocessing.StandardScaler().fit(X).transform(X)\n",
    "X[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b6E06JgxZsoT"
   },
   "source": [
    "# 4. Train /Test dataset\n",
    "Bien, dividimos nuestro conjunto de datos en tren y conjunto de prueba:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GCaMu5yUZ73v",
    "outputId": "16b0d8a8-143c-4ab4-fb28-2272a780d023"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: (160, 7) (160,)\n",
      "Test set: (40, 7) (40,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, random_state=4)\n",
    "print ('Train set:', X_train.shape,  y_train.shape)\n",
    "print ('Test set:', X_test.shape,  y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HeQl5KivZ-Qv"
   },
   "source": [
    "# 5. Modelado Regresi√≥n Log√≠stica con scikit-learn\n",
    "\n",
    "Construyamos nuestro modelo usando LogisticRegression del paquete Scikit-learn. Esta funci√≥n implementa la regresi√≥n log√≠stica y puede usar diferentes optimizadores num√©ricos para encontrar par√°metros, incluidos los solucionadores \"newton-cg\", \"lbfgs\", \"liblinear\", \"sag\" y \"saga\". Puede encontrar amplia informaci√≥n sobre los pros y los contras de estos optimizadores si lo busca en Internet.\n",
    "\n",
    "La versi√≥n de Regresi√≥n log√≠stica en Scikit-learn, admite regularizaci√≥n. La regularizaci√≥n es una t√©cnica utilizada para resolver el problema de sobreajuste en modelos de aprendizaje autom√°tico. El par√°metro C indica el inverso de la fuerza de regularizaci√≥n, que debe ser un valor flotante positivo. Los valores m√°s peque√±os especifican una regularizaci√≥n m√°s fuerte. Ahora ajustemos nuestro modelo con juego de trenes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EzMKmPXyaOu7",
    "outputId": "e62fb37b-0491-4af5-cca9-5af54bdd8f53"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.01, solver='liblinear')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "LR = LogisticRegression(C=0.01, solver='liblinear').fit(X_train,y_train)\n",
    "LR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_us9NXPUaUDn"
   },
   "source": [
    "Ahora podemos predecir usando nuestro conjunto de prueba:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5p9duWWQabwb",
    "outputId": "cf14a85c-ed65-42e5-e41c-bfb3586b26bb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat = LR.predict(X_test)\n",
    "yhat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sfKIGuWDaiwI"
   },
   "source": [
    "predict_prob devuelve estimaciones para todas las clases, ordenadas por la etiqueta de clases. Entonces, la primera columna es la probabilidad de la clase 1, P (Y = 1 | X), y la segunda columna es la probabilidad de la clase 0, P (Y = 0 | X):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BGuaOB3Vahi2",
    "outputId": "134c9294-db58-4dea-b982-f088a91cc4a5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.54132919, 0.45867081],\n",
       "       [0.60593357, 0.39406643],\n",
       "       [0.56277713, 0.43722287],\n",
       "       [0.63432489, 0.36567511],\n",
       "       [0.56431839, 0.43568161],\n",
       "       [0.55386646, 0.44613354],\n",
       "       [0.52237207, 0.47762793],\n",
       "       [0.60514349, 0.39485651],\n",
       "       [0.41069572, 0.58930428],\n",
       "       [0.6333873 , 0.3666127 ],\n",
       "       [0.58068791, 0.41931209],\n",
       "       [0.62768628, 0.37231372],\n",
       "       [0.47559883, 0.52440117],\n",
       "       [0.4267593 , 0.5732407 ],\n",
       "       [0.66172417, 0.33827583],\n",
       "       [0.55092315, 0.44907685],\n",
       "       [0.51749946, 0.48250054],\n",
       "       [0.485743  , 0.514257  ],\n",
       "       [0.49011451, 0.50988549],\n",
       "       [0.52423349, 0.47576651],\n",
       "       [0.61619519, 0.38380481],\n",
       "       [0.52696302, 0.47303698],\n",
       "       [0.63957168, 0.36042832],\n",
       "       [0.52205164, 0.47794836],\n",
       "       [0.50572852, 0.49427148],\n",
       "       [0.70706202, 0.29293798],\n",
       "       [0.55266286, 0.44733714],\n",
       "       [0.52271594, 0.47728406],\n",
       "       [0.51638863, 0.48361137],\n",
       "       [0.71331391, 0.28668609],\n",
       "       [0.67862111, 0.32137889],\n",
       "       [0.50896403, 0.49103597],\n",
       "       [0.42348082, 0.57651918],\n",
       "       [0.71495838, 0.28504162],\n",
       "       [0.59711064, 0.40288936],\n",
       "       [0.63808839, 0.36191161],\n",
       "       [0.39957895, 0.60042105],\n",
       "       [0.52127638, 0.47872362],\n",
       "       [0.65975464, 0.34024536],\n",
       "       [0.5114172 , 0.4885828 ]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat_prob = LR.predict_proba(X_test)\n",
    "yhat_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SZx9lJQdarQe"
   },
   "source": [
    "# 6. Evaluaci√≥n \n",
    "\n",
    "# Indice de Jaccard\n",
    "Probemos el √≠ndice jaccard para evaluar la precisi√≥n. podemos definir jaccard como el tama√±o de la intersecci√≥n dividido por el tama√±o de la uni√≥n de dos conjuntos de etiquetas. Si todo el conjunto de etiquetas predichas para una muestra coincide estrictamente con el conjunto verdadero de etiquetas, entonces la precisi√≥n del subconjunto es 1.0; de lo contrario, es 0.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8ABqNfaeacX8",
    "outputId": "019872f7-205c-4caf-c762-79f7930da993"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.375"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#colab\n",
    "#from sklearn.metrics import jaccard_similarity_score\n",
    "#jaccard_similarity_score(y_test, yhat)\n",
    "#local\n",
    "from sklearn.metrics import jaccard_score\n",
    "jaccard_score(y_test, yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_8qtSCAZbOV-"
   },
   "source": [
    "# 7. matriz de confusi√≥n \n",
    "Otra forma de ver la precisi√≥n del clasificador es mirar la matriz de confusi√≥n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1M5_Rt1cbj22",
    "outputId": "4bd75034-8d66-47cd-cd54-a755426aadcc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 6  9]\n",
      " [ 1 24]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import itertools\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "print(confusion_matrix(y_test, yhat, labels=[1,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 362
    },
    "id": "yPEp0sUgbqim",
    "outputId": "0a9d8f3c-7d36-4b21-f0ff-6737e6f58742"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[ 6  9]\n",
      " [ 1 24]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(y_test, yhat, labels=[1,0])\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=['churn=1','churn=0'],normalize= False,  title='Confusion matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vBO8Grz6cR_Y"
   },
   "source": [
    "Mira la primera fila. La primera fila es para los clientes cuyo valor de abandono real en el conjunto de prueba es 1. Como puede calcular, de 40 clientes, el valor de abandono de 15 de ellos es 1. Y de estos 15, el clasificador predijo correctamente 6 de ellos como 1 y 9 de ellos como 0.\n",
    "\n",
    "Significa que, para 6 clientes, el valor de abandono real fue 1 en el conjunto de prueba, y el clasificador tambi√©n predijo correctamente esos como 1. Sin embargo, mientras que la etiqueta real de 9 clientes fue 1, el clasificador predijo esos como 0, lo que no es muy bueno . Podemos considerarlo como un error del modelo de la primera fila.\n",
    "\n",
    "¬øQu√© pasa con los clientes con valor de deserci√≥n 0? Veamos la segunda fila. Parece que hubo 25 clientes cuyo valor de abandono fue 0.\n",
    "\n",
    "El clasificador predijo correctamente 24 de ellos como 0 y uno de ellos incorrectamente como 1. Por lo tanto, ha hecho un buen trabajo al predecir los clientes con un valor de rotaci√≥n 0. Lo bueno de la matriz de confusi√≥n es que muestra la capacidad del modelo para predecir correctamente o separar las clases. En un caso espec√≠fico de clasificador binario, como este ejemplo, podemos interpretar estos n√∫meros como el recuento de verdaderos positivos, falsos positivos, verdaderos negativos y falsos negativos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Otj2-nOybqgp",
    "outputId": "5ad71485-8da4-49b7-926e-fc0aac9c64fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.96      0.83        25\n",
      "           1       0.86      0.40      0.55        15\n",
      "\n",
      "    accuracy                           0.75        40\n",
      "   macro avg       0.79      0.68      0.69        40\n",
      "weighted avg       0.78      0.75      0.72        40\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (classification_report(y_test, yhat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yp8rJpxGccdi"
   },
   "source": [
    "Bas√°ndonos en el recuento de cada secci√≥n, podemos calcular la precisi√≥n y la recuperaci√≥n de cada etiqueta:\n",
    "\n",
    "* **PRECISION** es una medida de la precisi√≥n siempre que se haya predicho una etiqueta de clase. Est√° definido por: precisi√≥n = TP / (TP + FP)\n",
    "\n",
    "* **RECALL** es una verdadera tasa positiva. Se define como: Recuperaci√≥n = TP / (TP + FN)\n",
    "\n",
    "Entonces, podemos calcular la precisi√≥n y la recuperaci√≥n de cada clase.\n",
    "\n",
    "**F1 score**: ahora estamos en condiciones de calcular los puntajes F1 para cada etiqueta en funci√≥n de la precisi√≥n y el recuerdo de esa etiqueta.\n",
    "\n",
    "La puntuaci√≥n F1 es el promedio arm√≥nico de la precisi√≥n y la recuperaci√≥n, donde una puntuaci√≥n F1 alcanza su mejor valor en 1 (precisi√≥n y recuperaci√≥n perfecta) y el peor en 0. Es una buena forma de demostrar que un clasificador tiene un buen valor para ambos recuerdo y precisi√≥n.\n",
    "\n",
    "Y finalmente, podemos decir que la precisi√≥n promedio para este clasificador es el promedio de la puntuaci√≥n F1 para ambas etiquetas, que es 0,72 en nuestro caso.\n",
    "\n",
    "# Log loss\n",
    "Ahora, intentemos la p√©rdida de registros para su evaluaci√≥n. En la regresi√≥n log√≠stica, el resultado puede ser que la probabilidad de que el cliente abandone sea s√≠ (o igual a 1). Esta probabilidad es un valor entre 0 y 1. La p√©rdida logar√≠tmica (p√©rdida logar√≠tmica) mide el rendimiento de un clasificador donde la salida prevista es un valor de probabilidad entre 0 y 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nBDW0Cjzcxzr",
    "outputId": "050d0381-daf0-4547-9a02-0be9f91b8ce3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6017092478101187"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "log_loss(y_test, yhat_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9aNeG0iuc49O"
   },
   "source": [
    "# Pr√°ctica\n",
    "Intente volver a crear el modelo de regresi√≥n log√≠stica para el mismo conjunto de datos, pero esta vez, ¬øusar√° diferentes valores de __solver__ y __regularization__? ¬øCu√°l es el nuevo valor de __logLoss__?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "KCUmdQVmdRt3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogLoss: : 0.61\n"
     ]
    }
   ],
   "source": [
    "# Escribi tu codigo\n",
    "LR2 = LogisticRegression(C=0.01, solver='sag').fit(X_train,y_train)\n",
    "yhat_prob2 = LR2.predict_proba(X_test)\n",
    "print (\"LogLoss: : %.2f\" % log_loss(y_test, yhat_prob2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e8F5lBHqdWiC"
   },
   "source": [
    "# Gracias por su atenci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WpGh51FUdY9-"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNJ0lN01O0FnSjIpIHQ+3I9",
   "include_colab_link": true,
   "name": "Lab_12_Log√≠stica_Regresi√≥n.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
